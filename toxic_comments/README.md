# Определение токсичных комментариев

## Описание проекта

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. 

Обучим модель классифицировать комментарии на позитивные и негативные. В нашем распоряжении набор данных с разметкой о токсичности.

## Описание данных

Данные находятся в файле `toxic_comments.csv`. Столбец *text* содержит текст комментария, а *toxic* — целевой признак.

## Оценка
Значение метрики качества *F1* должно быть не меньше 0.75 на тестовой выборке. 

Получили *F1* больше 0.76, качество удовлетворительное.

## Ход работы и выводы по проекту

1. Полученные данные не содержали пропусков и дубликатов. Язык текстов - английский.
2. Очистили тексты от лишних символов, привели все к нижнему регистру, лемматизировали. Разделили данные на тренировочную и тестовую выборки с учетом дисбаланса классов.  
3. Построили пайплайн для векторизации текстов и обучения моделей. Перебрали гиперпараметры для логистической регрессии и дерева решений, получили на кросс-валидации результаты, превышающие необходимый порог качества. 
4. Результат на тестовой выборке также удовлетворительный. Остановились на модели логистической регрессии с параметром *C*=3. 
5. Построили матрицу ошибок модели. Определили, что в абсолютном выражении модель чаще допускает ошибки первого рода, чем второго рода; но хуже распознает объекты класса 1, чем объекты класса 0.

## Рекомендации
1. Обученную модель можно применять для определения токсичных комментариев.
2. При необходимости повышения качества предсказаний можно использовать сэмплирование.
